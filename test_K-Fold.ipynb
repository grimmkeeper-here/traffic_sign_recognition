{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Library done\n"
     ]
    }
   ],
   "source": [
    "# Libraries for Keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Another\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "print(\"Import Library done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data class 0\n",
      "Load Data class 1\n",
      "Load Data class 2\n",
      "Load Data class 3\n",
      "Load Data class 4\n",
      "Load Data class 5\n",
      "Load Data class 6\n",
      "Load Data class 7\n",
      "Load Data class 8\n",
      "Load Data class 9\n",
      "Load Data class 10\n",
      "Load Data class 11\n",
      "Load Data class 12\n",
      "Load Data class 13\n",
      "Load Data class 14\n",
      "Load Data class 15\n",
      "Load Data class 16\n",
      "Load Data class 17\n",
      "Load Data class 18\n",
      "Load Data class 19\n",
      "Load Data class 20\n",
      "Load Data class 21\n",
      "Load Data class 22\n",
      "Load Data class 23\n",
      "Load Data class 24\n",
      "Load Data class 25\n",
      "Load Data class 26\n",
      "Load Data class 27\n",
      "Load Data class 28\n",
      "Load Data class 29\n",
      "Load Data class 30\n",
      "Load Data class 31\n",
      "Load Data class 32\n",
      "Load Data class 33\n",
      "Load Data class 34\n",
      "Load Data class 35\n",
      "Load Data class 36\n",
      "Load Data class 37\n",
      "Load Data class 38\n",
      "Load Data class 39\n",
      "Load Data class 40\n",
      "Load Data class 41\n",
      "Load Data class 42\n",
      "Load Data Success\n"
     ]
    }
   ],
   "source": [
    "# Define\n",
    "## Constant\n",
    "### Input Image Size\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "### Class Amount\n",
    "classes = 43\n",
    "### Ratio to split Data Train into 2 part Train and Val: 80% to train and 20% to val.\n",
    "ratio = 0.2\n",
    "\n",
    "## Variable\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "# Main\n",
    "## Reading the input images and putting them into a numpy array\n",
    "for i in range(classes) :\n",
    "    path = \"./input/train/{0}/\".format(i)\n",
    "    print(\"Load Data class {}\".format(i))\n",
    "    Class=os.listdir(path)\n",
    "    for a in Class:\n",
    "        try:\n",
    "            image=cv2.imread(path+a)\n",
    "            image_from_array = Image.fromarray(image, 'RGB')\n",
    "            size_image = image_from_array.resize((height, width))\n",
    "            data.append(np.array(size_image))\n",
    "            labels.append(i)\n",
    "        except AttributeError:\n",
    "            print(\" \")            \n",
    "Cells=np.array(data)\n",
    "labels=np.array(labels)\n",
    "print(\"Load Data Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Test Data\n"
     ]
    }
   ],
   "source": [
    "# Define\n",
    "## Variable\n",
    "data=[]\n",
    "\n",
    "# Main\n",
    "## Load Test Data\n",
    "print(\"Load Test Data\")\n",
    "y_test=pd.read_csv(\"./input/Test.csv\")\n",
    "_labels=y_test['Path'].values\n",
    "y_test=y_test['ClassId'].values\n",
    "for f in _labels:\n",
    "    path ='./input/test/'+f.replace('Test/', '')\n",
    "    image=cv2.imread(path)\n",
    "    image_from_array = Image.fromarray(image, 'RGB')\n",
    "    size_image = image_from_array.resize((height, width))\n",
    "    data.append(np.array(size_image))\n",
    "\n",
    "X_test=np.array(data)\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 200\n",
    "## Compilation of the model\n",
    "adam = Adam(lr=0.002)\n",
    "max_score = 0.0\n",
    "data_score = []\n",
    "\n",
    "def trainModel(X_train, X_val, y_train, y_val,X_test,y_test):\n",
    "    global max_score\n",
    "    global data_score\n",
    "    \n",
    "    ## Prepare Data\n",
    "    X_train = X_train.astype('float32')/255 \n",
    "    X_val = X_val.astype('float32')/255\n",
    "    y_train = to_categorical(y_train, classes)\n",
    "    y_val = to_categorical(y_val, classes)\n",
    "    \n",
    "    ## Create Model\n",
    "    model = Sequential()\n",
    "    # Layer 1: Convolutional. Input = 32x32x3. Output = 28x28x6. Activation = RELU.\n",
    "    model.add(Conv2D(filters=6, kernel_size=(5,5),strides=1, padding='valid', activation='relu', input_shape=X_train.shape[1:]))\n",
    "    # Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    model.add(MaxPool2D(pool_size=(2, 2),strides=2, padding='valid'))\n",
    "    # Layer 2: Convolutional. Output = 10x10x16. Activation = RELU.\n",
    "    model.add(Conv2D(filters=16, kernel_size=(5,5),strides=1, padding='valid', activation='relu'))\n",
    "    # Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    model.add(MaxPool2D(pool_size=(2, 2),strides=2, padding='valid'))\n",
    "    # Flatten. Input = 5x5x16. Output = 400.\n",
    "    model.add(Flatten())\n",
    "    # Layer 3: Fully Connected. Input = 400. Output = 120. Activation = RELU.\n",
    "    model.add(Dense(120, activation='relu'))\n",
    "    # Layer 4: Fully Connected. Input = 120. Output = 84. Activation = RELU.\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    # Layer 5: Fully Connected. Input = 84. Output = 43.\n",
    "    model.add(Dense(43, activation='softmax'))\n",
    "    model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=adam, \n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    ## Train Model\n",
    "    history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS,validation_data=(X_val, y_val))\n",
    "    \n",
    "    ## Predict\n",
    "    pred = model.predict_classes(X_test)\n",
    "    score = accuracy_score(y_test, pred)\n",
    "    data_score.append(score)\n",
    "    print(\"Test Accuracy: {0}\".format(score))\n",
    "    \n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        ## Save Model\n",
    "        model.save(\"./model/model.h5\")\n",
    "        print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model part 1: \n",
      "Train on 31367 samples, validate on 7842 samples\n",
      "Epoch 1/50\n",
      "31367/31367 [==============================] - 8s 269us/step - loss: 1.9046 - accuracy: 0.4934 - val_loss: 0.8578 - val_accuracy: 0.7497\n",
      "Epoch 2/50\n",
      "31367/31367 [==============================] - 8s 262us/step - loss: 0.5733 - accuracy: 0.8370 - val_loss: 0.4246 - val_accuracy: 0.8783\n",
      "Epoch 3/50\n",
      "31367/31367 [==============================] - 8s 260us/step - loss: 0.3147 - accuracy: 0.9134 - val_loss: 0.2888 - val_accuracy: 0.9231\n",
      "Epoch 4/50\n",
      "31367/31367 [==============================] - 8s 261us/step - loss: 0.2249 - accuracy: 0.9384 - val_loss: 0.2203 - val_accuracy: 0.9401\n",
      "Epoch 5/50\n",
      "31367/31367 [==============================] - 8s 262us/step - loss: 0.1525 - accuracy: 0.9583 - val_loss: 0.1980 - val_accuracy: 0.9452\n",
      "Epoch 6/50\n",
      "31367/31367 [==============================] - 8s 262us/step - loss: 0.1150 - accuracy: 0.9695 - val_loss: 0.1626 - val_accuracy: 0.9566\n",
      "Epoch 7/50\n",
      "31367/31367 [==============================] - 8s 261us/step - loss: 0.0957 - accuracy: 0.9740 - val_loss: 0.1493 - val_accuracy: 0.9631\n",
      "Epoch 8/50\n",
      "31367/31367 [==============================] - 8s 262us/step - loss: 0.0811 - accuracy: 0.9769 - val_loss: 0.1285 - val_accuracy: 0.9684\n",
      "Epoch 9/50\n",
      "31367/31367 [==============================] - 8s 262us/step - loss: 0.0663 - accuracy: 0.9809 - val_loss: 0.1270 - val_accuracy: 0.9699\n",
      "Epoch 10/50\n",
      "31367/31367 [==============================] - 8s 263us/step - loss: 0.0577 - accuracy: 0.9834 - val_loss: 0.1367 - val_accuracy: 0.9668\n",
      "Epoch 11/50\n",
      "31367/31367 [==============================] - 8s 263us/step - loss: 0.0501 - accuracy: 0.9859 - val_loss: 0.1111 - val_accuracy: 0.9730\n",
      "Epoch 12/50\n",
      "31367/31367 [==============================] - 8s 263us/step - loss: 0.0366 - accuracy: 0.9893 - val_loss: 0.1231 - val_accuracy: 0.9694\n",
      "Epoch 13/50\n",
      "31367/31367 [==============================] - 8s 263us/step - loss: 0.0359 - accuracy: 0.9894 - val_loss: 0.1077 - val_accuracy: 0.9764\n",
      "Epoch 14/50\n",
      "31367/31367 [==============================] - 8s 264us/step - loss: 0.0376 - accuracy: 0.9887 - val_loss: 0.1118 - val_accuracy: 0.9749\n",
      "Epoch 15/50\n",
      "31367/31367 [==============================] - 8s 264us/step - loss: 0.0294 - accuracy: 0.9913 - val_loss: 0.1418 - val_accuracy: 0.9693\n",
      "Epoch 16/50\n",
      "31367/31367 [==============================] - 8s 263us/step - loss: 0.0382 - accuracy: 0.9880 - val_loss: 0.1232 - val_accuracy: 0.9751\n",
      "Epoch 17/50\n",
      "31367/31367 [==============================] - 8s 263us/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 0.1285 - val_accuracy: 0.9759\n",
      "Epoch 18/50\n",
      "31367/31367 [==============================] - 8s 264us/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.1043 - val_accuracy: 0.9791\n",
      "Epoch 19/50\n",
      "31367/31367 [==============================] - 8s 263us/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.1163 - val_accuracy: 0.9762\n",
      "Epoch 20/50\n",
      "31367/31367 [==============================] - 8s 265us/step - loss: 0.0158 - accuracy: 0.9955 - val_loss: 0.1114 - val_accuracy: 0.9742\n",
      "Epoch 21/50\n",
      "31367/31367 [==============================] - 8s 264us/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 0.1233 - val_accuracy: 0.9744\n",
      "Epoch 22/50\n",
      "31367/31367 [==============================] - 8s 264us/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 0.1161 - val_accuracy: 0.9784\n",
      "Epoch 23/50\n",
      "31367/31367 [==============================] - 8s 264us/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.1482 - val_accuracy: 0.9748\n",
      "Epoch 24/50\n",
      "31367/31367 [==============================] - 8s 264us/step - loss: 0.0226 - accuracy: 0.9930 - val_loss: 0.1158 - val_accuracy: 0.9768\n",
      "Epoch 25/50\n",
      "31367/31367 [==============================] - 8s 269us/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.1245 - val_accuracy: 0.9745\n",
      "Epoch 26/50\n",
      "31367/31367 [==============================] - 8s 266us/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.1163 - val_accuracy: 0.9795\n",
      "Epoch 27/50\n",
      "31367/31367 [==============================] - 8s 264us/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.1270 - val_accuracy: 0.9778\n",
      "Epoch 28/50\n",
      "31367/31367 [==============================] - 8s 265us/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.1586 - val_accuracy: 0.9690\n",
      "Epoch 29/50\n",
      "31367/31367 [==============================] - 8s 265us/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.1258 - val_accuracy: 0.9778\n",
      "Epoch 30/50\n",
      "31367/31367 [==============================] - 8s 271us/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.1124 - val_accuracy: 0.9802\n",
      "Epoch 31/50\n",
      "31367/31367 [==============================] - 8s 265us/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.1132 - val_accuracy: 0.9807\n",
      "Epoch 32/50\n",
      "31367/31367 [==============================] - 8s 263us/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.1307 - val_accuracy: 0.9774\n",
      "Epoch 33/50\n",
      "31367/31367 [==============================] - 8s 266us/step - loss: 0.0246 - accuracy: 0.9924 - val_loss: 0.1345 - val_accuracy: 0.9763\n",
      "Epoch 34/50\n",
      "31367/31367 [==============================] - 8s 265us/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.1193 - val_accuracy: 0.9795\n",
      "Epoch 35/50\n",
      "31367/31367 [==============================] - 8s 268us/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.1190 - val_accuracy: 0.9768\n",
      "Epoch 36/50\n",
      "31367/31367 [==============================] - 8s 271us/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.1625 - val_accuracy: 0.9730\n",
      "Epoch 37/50\n",
      "31367/31367 [==============================] - 8s 266us/step - loss: 0.0242 - accuracy: 0.9930 - val_loss: 0.1197 - val_accuracy: 0.9806\n",
      "Epoch 38/50\n",
      "31367/31367 [==============================] - 8s 265us/step - loss: 0.0283 - accuracy: 0.9923 - val_loss: 0.1140 - val_accuracy: 0.9821\n",
      "Epoch 39/50\n",
      "31367/31367 [==============================] - 8s 268us/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 0.1157 - val_accuracy: 0.9820\n",
      "Epoch 40/50\n",
      "31367/31367 [==============================] - 8s 266us/step - loss: 0.0260 - accuracy: 0.9931 - val_loss: 0.1307 - val_accuracy: 0.9765\n",
      "Epoch 41/50\n",
      "31367/31367 [==============================] - 8s 265us/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.1105 - val_accuracy: 0.9829\n",
      "Epoch 42/50\n",
      "31367/31367 [==============================] - 8s 266us/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.1217 - val_accuracy: 0.9843\n",
      "Epoch 43/50\n",
      "31367/31367 [==============================] - 8s 267us/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.1420 - val_accuracy: 0.9819\n",
      "Epoch 44/50\n",
      "31367/31367 [==============================] - 8s 265us/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.1301 - val_accuracy: 0.9807\n",
      "Epoch 45/50\n",
      "31367/31367 [==============================] - 8s 265us/step - loss: 0.0302 - accuracy: 0.9917 - val_loss: 0.1759 - val_accuracy: 0.9727\n",
      "Epoch 46/50\n",
      "31367/31367 [==============================] - 8s 266us/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.1342 - val_accuracy: 0.9802\n",
      "Epoch 47/50\n",
      "31367/31367 [==============================] - 8s 266us/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1088 - val_accuracy: 0.9858\n",
      "Epoch 48/50\n",
      "31367/31367 [==============================] - 8s 267us/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.1159 - val_accuracy: 0.9864\n",
      "Epoch 49/50\n",
      "31367/31367 [==============================] - 8s 266us/step - loss: 3.4880e-04 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9864\n",
      "Epoch 50/50\n",
      "31367/31367 [==============================] - 8s 266us/step - loss: 1.6288e-04 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9875\n",
      "Test Accuracy: 0.9315122723673792\n",
      "Saved model to disk\n",
      "Train model part 2: \n",
      "Train on 31367 samples, validate on 7842 samples\n",
      "Epoch 1/50\n",
      "31367/31367 [==============================] - 8s 264us/step - loss: 2.2382 - accuracy: 0.3697 - val_loss: 1.1223 - val_accuracy: 0.6554\n",
      "Epoch 2/50\n",
      "31367/31367 [==============================] - 8s 263us/step - loss: 0.8161 - accuracy: 0.7512 - val_loss: 0.6553 - val_accuracy: 0.8082\n",
      "Epoch 3/50\n",
      "31367/31367 [==============================] - 8s 261us/step - loss: 0.5156 - accuracy: 0.8481 - val_loss: 0.4764 - val_accuracy: 0.8595\n",
      "Epoch 4/50\n",
      "31367/31367 [==============================] - 8s 260us/step - loss: 0.3809 - accuracy: 0.8872 - val_loss: 0.3862 - val_accuracy: 0.8919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "31367/31367 [==============================] - 8s 258us/step - loss: 0.3119 - accuracy: 0.9060 - val_loss: 0.3655 - val_accuracy: 0.8933\n",
      "Epoch 6/50\n",
      "31367/31367 [==============================] - 8s 258us/step - loss: 0.2573 - accuracy: 0.9228 - val_loss: 0.3116 - val_accuracy: 0.9142\n",
      "Epoch 7/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.2131 - accuracy: 0.9360 - val_loss: 0.2712 - val_accuracy: 0.9232\n",
      "Epoch 8/50\n",
      "31367/31367 [==============================] - 8s 257us/step - loss: 0.1837 - accuracy: 0.9438 - val_loss: 0.2627 - val_accuracy: 0.9262\n",
      "Epoch 9/50\n",
      "31367/31367 [==============================] - 8s 258us/step - loss: 0.1631 - accuracy: 0.9488 - val_loss: 0.2696 - val_accuracy: 0.9235\n",
      "Epoch 10/50\n",
      "31367/31367 [==============================] - 8s 258us/step - loss: 0.1442 - accuracy: 0.9555 - val_loss: 0.2305 - val_accuracy: 0.9339\n",
      "Epoch 11/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.1234 - accuracy: 0.9605 - val_loss: 0.2407 - val_accuracy: 0.9324\n",
      "Epoch 12/50\n",
      "31367/31367 [==============================] - 8s 257us/step - loss: 0.1141 - accuracy: 0.9641 - val_loss: 0.2422 - val_accuracy: 0.9370\n",
      "Epoch 13/50\n",
      "31367/31367 [==============================] - 8s 258us/step - loss: 0.1018 - accuracy: 0.9667 - val_loss: 0.2213 - val_accuracy: 0.9376\n",
      "Epoch 14/50\n",
      "31367/31367 [==============================] - 8s 258us/step - loss: 0.0923 - accuracy: 0.9703 - val_loss: 0.2149 - val_accuracy: 0.9421\n",
      "Epoch 15/50\n",
      "31367/31367 [==============================] - 8s 257us/step - loss: 0.0810 - accuracy: 0.9736 - val_loss: 0.2427 - val_accuracy: 0.9404\n",
      "Epoch 16/50\n",
      "31367/31367 [==============================] - 8s 258us/step - loss: 0.0764 - accuracy: 0.9751 - val_loss: 0.2336 - val_accuracy: 0.9411\n",
      "Epoch 17/50\n",
      "31367/31367 [==============================] - 8s 257us/step - loss: 0.0707 - accuracy: 0.9767 - val_loss: 0.2317 - val_accuracy: 0.9438\n",
      "Epoch 18/50\n",
      "31367/31367 [==============================] - 8s 258us/step - loss: 0.0664 - accuracy: 0.9779 - val_loss: 0.2446 - val_accuracy: 0.9440\n",
      "Epoch 19/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.0594 - accuracy: 0.9798 - val_loss: 0.2227 - val_accuracy: 0.9482\n",
      "Epoch 20/50\n",
      "31367/31367 [==============================] - 8s 260us/step - loss: 0.0527 - accuracy: 0.9830 - val_loss: 0.2523 - val_accuracy: 0.9463\n",
      "Epoch 21/50\n",
      "31367/31367 [==============================] - 8s 258us/step - loss: 0.0499 - accuracy: 0.9837 - val_loss: 0.2569 - val_accuracy: 0.9455\n",
      "Epoch 22/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.0491 - accuracy: 0.9837 - val_loss: 0.2540 - val_accuracy: 0.9455\n",
      "Epoch 23/50\n",
      "31367/31367 [==============================] - 8s 260us/step - loss: 0.0489 - accuracy: 0.9842 - val_loss: 0.2687 - val_accuracy: 0.9461\n",
      "Epoch 24/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.0512 - accuracy: 0.9827 - val_loss: 0.2593 - val_accuracy: 0.9491\n",
      "Epoch 25/50\n",
      "31367/31367 [==============================] - 8s 260us/step - loss: 0.0387 - accuracy: 0.9869 - val_loss: 0.2443 - val_accuracy: 0.9519\n",
      "Epoch 26/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.0328 - accuracy: 0.9891 - val_loss: 0.2957 - val_accuracy: 0.9438\n",
      "Epoch 27/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.0345 - accuracy: 0.9892 - val_loss: 0.2705 - val_accuracy: 0.9486\n",
      "Epoch 28/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.2805 - val_accuracy: 0.9472\n",
      "Epoch 29/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.0355 - accuracy: 0.9886 - val_loss: 0.3062 - val_accuracy: 0.9440\n",
      "Epoch 30/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.0330 - accuracy: 0.9888 - val_loss: 0.2576 - val_accuracy: 0.9540\n",
      "Epoch 31/50\n",
      "31367/31367 [==============================] - 8s 260us/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.2621 - val_accuracy: 0.9495\n",
      "Epoch 32/50\n",
      "31367/31367 [==============================] - 8s 260us/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.2787 - val_accuracy: 0.9537\n",
      "Epoch 33/50\n",
      "31367/31367 [==============================] - 8s 261us/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 0.2835 - val_accuracy: 0.9498\n",
      "Epoch 34/50\n",
      "31367/31367 [==============================] - 8s 261us/step - loss: 0.0358 - accuracy: 0.9883 - val_loss: 0.3634 - val_accuracy: 0.9362\n",
      "Epoch 35/50\n",
      "31367/31367 [==============================] - 8s 260us/step - loss: 0.0484 - accuracy: 0.9846 - val_loss: 0.3149 - val_accuracy: 0.9463\n",
      "Epoch 36/50\n",
      "31367/31367 [==============================] - 8s 261us/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 0.2953 - val_accuracy: 0.9514\n",
      "Epoch 37/50\n",
      "31367/31367 [==============================] - 8s 261us/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.2730 - val_accuracy: 0.9546\n",
      "Epoch 38/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.3432 - val_accuracy: 0.9425\n",
      "Epoch 39/50\n",
      "31367/31367 [==============================] - 8s 261us/step - loss: 0.0210 - accuracy: 0.9935 - val_loss: 0.3004 - val_accuracy: 0.9531\n",
      "Epoch 40/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.3009 - val_accuracy: 0.9522\n",
      "Epoch 41/50\n",
      "31367/31367 [==============================] - 8s 260us/step - loss: 0.0309 - accuracy: 0.9894 - val_loss: 0.2925 - val_accuracy: 0.9533\n",
      "Epoch 42/50\n",
      "31367/31367 [==============================] - 8s 262us/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.2624 - val_accuracy: 0.9578\n",
      "Epoch 43/50\n",
      "31367/31367 [==============================] - 8s 260us/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.2678 - val_accuracy: 0.9589\n",
      "Epoch 44/50\n",
      "31367/31367 [==============================] - 8s 262us/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.2685 - val_accuracy: 0.9597\n",
      "Epoch 45/50\n",
      "31367/31367 [==============================] - 8s 262us/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.2700 - val_accuracy: 0.9623\n",
      "Epoch 46/50\n",
      "31367/31367 [==============================] - 8s 260us/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.2813 - val_accuracy: 0.9615\n",
      "Epoch 47/50\n",
      "31367/31367 [==============================] - 8s 261us/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.3593 - val_accuracy: 0.9509\n",
      "Epoch 48/50\n",
      "31367/31367 [==============================] - 8s 260us/step - loss: 0.0901 - accuracy: 0.9751 - val_loss: 0.3540 - val_accuracy: 0.9438\n",
      "Epoch 49/50\n",
      "31367/31367 [==============================] - 8s 261us/step - loss: 0.0401 - accuracy: 0.9873 - val_loss: 0.2860 - val_accuracy: 0.9543\n",
      "Epoch 50/50\n",
      "31367/31367 [==============================] - 8s 262us/step - loss: 0.0183 - accuracy: 0.9934 - val_loss: 0.2815 - val_accuracy: 0.9584\n",
      "Test Accuracy: 0.8646872525732383\n",
      "Train model part 3: \n",
      "Train on 31367 samples, validate on 7842 samples\n",
      "Epoch 1/50\n",
      "31367/31367 [==============================] - 9s 280us/step - loss: 1.8461 - accuracy: 0.4710 - val_loss: 0.8365 - val_accuracy: 0.7447\n",
      "Epoch 2/50\n",
      "31367/31367 [==============================] - 8s 270us/step - loss: 0.6282 - accuracy: 0.8067 - val_loss: 0.5433 - val_accuracy: 0.8365\n",
      "Epoch 3/50\n",
      "31367/31367 [==============================] - 8s 262us/step - loss: 0.4206 - accuracy: 0.8734 - val_loss: 0.4240 - val_accuracy: 0.8740\n",
      "Epoch 4/50\n",
      "31367/31367 [==============================] - 8s 267us/step - loss: 0.3255 - accuracy: 0.9026 - val_loss: 0.3603 - val_accuracy: 0.8971\n",
      "Epoch 5/50\n",
      "31367/31367 [==============================] - 8s 265us/step - loss: 0.2665 - accuracy: 0.9219 - val_loss: 0.3046 - val_accuracy: 0.9151\n",
      "Epoch 6/50\n",
      "31367/31367 [==============================] - 8s 261us/step - loss: 0.2275 - accuracy: 0.9326 - val_loss: 0.2923 - val_accuracy: 0.9211\n",
      "Epoch 7/50\n",
      "31367/31367 [==============================] - 8s 263us/step - loss: 0.1941 - accuracy: 0.9418 - val_loss: 0.2720 - val_accuracy: 0.9265\n",
      "Epoch 8/50\n",
      "31367/31367 [==============================] - 8s 262us/step - loss: 0.1767 - accuracy: 0.9462 - val_loss: 0.2592 - val_accuracy: 0.9297\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.1538 - accuracy: 0.9538 - val_loss: 0.2540 - val_accuracy: 0.9294\n",
      "Epoch 10/50\n",
      "31367/31367 [==============================] - 8s 258us/step - loss: 0.1425 - accuracy: 0.9565 - val_loss: 0.2519 - val_accuracy: 0.9334\n",
      "Epoch 11/50\n",
      "31367/31367 [==============================] - 8s 260us/step - loss: 0.1284 - accuracy: 0.9603 - val_loss: 0.2602 - val_accuracy: 0.9352\n",
      "Epoch 12/50\n",
      "31367/31367 [==============================] - 8s 260us/step - loss: 0.1183 - accuracy: 0.9619 - val_loss: 0.2462 - val_accuracy: 0.9376\n",
      "Epoch 13/50\n",
      "31367/31367 [==============================] - 8s 260us/step - loss: 0.1113 - accuracy: 0.9647 - val_loss: 0.2445 - val_accuracy: 0.9376\n",
      "Epoch 14/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.1058 - accuracy: 0.9675 - val_loss: 0.2498 - val_accuracy: 0.9382\n",
      "Epoch 15/50\n",
      "31367/31367 [==============================] - 8s 261us/step - loss: 0.0911 - accuracy: 0.9712 - val_loss: 0.2662 - val_accuracy: 0.9345\n",
      "Epoch 16/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.0858 - accuracy: 0.9723 - val_loss: 0.2860 - val_accuracy: 0.9320\n",
      "Epoch 17/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.0790 - accuracy: 0.9747 - val_loss: 0.2459 - val_accuracy: 0.9438\n",
      "Epoch 18/50\n",
      "31367/31367 [==============================] - 8s 259us/step - loss: 0.0702 - accuracy: 0.9762 - val_loss: 0.2431 - val_accuracy: 0.9452\n",
      "Epoch 19/50\n",
      "31367/31367 [==============================] - 9s 279us/step - loss: 0.0717 - accuracy: 0.9767 - val_loss: 0.2454 - val_accuracy: 0.9457\n",
      "Epoch 20/50\n",
      "31367/31367 [==============================] - 9s 298us/step - loss: 0.0636 - accuracy: 0.9799 - val_loss: 0.2536 - val_accuracy: 0.9450\n",
      "Epoch 21/50\n",
      "31367/31367 [==============================] - 9s 282us/step - loss: 0.0665 - accuracy: 0.9773 - val_loss: 0.2764 - val_accuracy: 0.9438\n",
      "Epoch 22/50\n",
      "31367/31367 [==============================] - 9s 279us/step - loss: 0.0569 - accuracy: 0.9815 - val_loss: 0.2651 - val_accuracy: 0.9475\n",
      "Epoch 23/50\n",
      "31367/31367 [==============================] - 10s 310us/step - loss: 0.0503 - accuracy: 0.9836 - val_loss: 0.2580 - val_accuracy: 0.9476\n",
      "Epoch 24/50\n",
      "31367/31367 [==============================] - 9s 274us/step - loss: 0.0514 - accuracy: 0.9827 - val_loss: 0.3011 - val_accuracy: 0.9411\n",
      "Epoch 25/50\n",
      "31367/31367 [==============================] - 11s 337us/step - loss: 0.0598 - accuracy: 0.9799 - val_loss: 0.2672 - val_accuracy: 0.9468\n",
      "Epoch 26/50\n",
      "31367/31367 [==============================] - 10s 329us/step - loss: 0.0531 - accuracy: 0.9815 - val_loss: 0.2781 - val_accuracy: 0.9453\n",
      "Epoch 27/50\n",
      "31367/31367 [==============================] - 10s 324us/step - loss: 0.0443 - accuracy: 0.9854 - val_loss: 0.2691 - val_accuracy: 0.9477\n",
      "Epoch 28/50\n",
      "31367/31367 [==============================] - 10s 324us/step - loss: 0.0423 - accuracy: 0.9860 - val_loss: 0.3045 - val_accuracy: 0.9467\n",
      "Epoch 29/50\n",
      "31367/31367 [==============================] - 9s 299us/step - loss: 0.0421 - accuracy: 0.9855 - val_loss: 0.2844 - val_accuracy: 0.9477\n",
      "Epoch 30/50\n",
      "31367/31367 [==============================] - 11s 336us/step - loss: 0.0474 - accuracy: 0.9835 - val_loss: 0.3230 - val_accuracy: 0.9453\n",
      "Epoch 31/50\n",
      "31367/31367 [==============================] - 10s 307us/step - loss: 0.0405 - accuracy: 0.9859 - val_loss: 0.2823 - val_accuracy: 0.9498\n",
      "Epoch 32/50\n",
      "31367/31367 [==============================] - 9s 299us/step - loss: 0.0350 - accuracy: 0.9885 - val_loss: 0.3070 - val_accuracy: 0.9476\n",
      "Epoch 33/50\n",
      "31367/31367 [==============================] - 9s 292us/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 0.2908 - val_accuracy: 0.9519\n",
      "Epoch 34/50\n",
      "31367/31367 [==============================] - 9s 294us/step - loss: 0.0476 - accuracy: 0.9842 - val_loss: 0.3268 - val_accuracy: 0.9467\n",
      "Epoch 35/50\n",
      "31367/31367 [==============================] - 9s 289us/step - loss: 0.0361 - accuracy: 0.9875 - val_loss: 0.2954 - val_accuracy: 0.9487\n",
      "Epoch 36/50\n",
      "31367/31367 [==============================] - 10s 306us/step - loss: 0.0279 - accuracy: 0.9905 - val_loss: 0.3083 - val_accuracy: 0.9478\n",
      "Epoch 37/50\n",
      "31367/31367 [==============================] - 9s 278us/step - loss: 0.0327 - accuracy: 0.9893 - val_loss: 0.3406 - val_accuracy: 0.9475\n",
      "Epoch 38/50\n",
      "31367/31367 [==============================] - 10s 306us/step - loss: 0.0493 - accuracy: 0.9838 - val_loss: 0.3482 - val_accuracy: 0.9425\n",
      "Epoch 39/50\n",
      "31367/31367 [==============================] - 9s 273us/step - loss: 0.0368 - accuracy: 0.9875 - val_loss: 0.3164 - val_accuracy: 0.9476\n",
      "Epoch 40/50\n",
      "31367/31367 [==============================] - 9s 274us/step - loss: 0.0263 - accuracy: 0.9912 - val_loss: 0.3028 - val_accuracy: 0.9531\n",
      "Epoch 41/50\n",
      "31367/31367 [==============================] - 9s 301us/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.3304 - val_accuracy: 0.9482\n",
      "Epoch 42/50\n",
      "31367/31367 [==============================] - 9s 274us/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.3333 - val_accuracy: 0.9486\n",
      "Epoch 43/50\n",
      "31367/31367 [==============================] - 9s 296us/step - loss: 0.0339 - accuracy: 0.9877 - val_loss: 0.3351 - val_accuracy: 0.9500\n",
      "Epoch 44/50\n",
      "31367/31367 [==============================] - 9s 283us/step - loss: 0.0504 - accuracy: 0.9846 - val_loss: 0.3332 - val_accuracy: 0.9491\n",
      "Epoch 45/50\n",
      "31367/31367 [==============================] - 9s 297us/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.3176 - val_accuracy: 0.9536\n",
      "Epoch 46/50\n",
      "31367/31367 [==============================] - 9s 291us/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.3221 - val_accuracy: 0.9499\n",
      "Epoch 47/50\n",
      "31367/31367 [==============================] - 10s 306us/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.3438 - val_accuracy: 0.9509\n",
      "Epoch 48/50\n",
      "31367/31367 [==============================] - 10s 312us/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.3031 - val_accuracy: 0.9561\n",
      "Epoch 49/50\n",
      "31367/31367 [==============================] - 9s 274us/step - loss: 0.0205 - accuracy: 0.9927 - val_loss: 0.3639 - val_accuracy: 0.9467\n",
      "Epoch 50/50\n",
      "31367/31367 [==============================] - 9s 278us/step - loss: 0.0481 - accuracy: 0.9844 - val_loss: 0.3775 - val_accuracy: 0.9401\n",
      "Test Accuracy: 0.8561361836896278\n",
      "Train model part 4: \n",
      "Train on 31367 samples, validate on 7842 samples\n",
      "Epoch 1/50\n",
      "31367/31367 [==============================] - 8s 268us/step - loss: 3.5068 - accuracy: 0.0541 - val_loss: 3.4936 - val_accuracy: 0.0573\n",
      "Epoch 2/50\n",
      "31367/31367 [==============================] - 8s 262us/step - loss: 3.4885 - accuracy: 0.0560 - val_loss: 3.4907 - val_accuracy: 0.0573\n",
      "Epoch 3/50\n",
      "31367/31367 [==============================] - 10s 309us/step - loss: 3.4877 - accuracy: 0.0575 - val_loss: 3.4910 - val_accuracy: 0.0562\n",
      "Epoch 4/50\n",
      "31367/31367 [==============================] - 10s 311us/step - loss: 3.4876 - accuracy: 0.0569 - val_loss: 3.4923 - val_accuracy: 0.0562\n",
      "Epoch 5/50\n",
      "31367/31367 [==============================] - 9s 280us/step - loss: 3.4871 - accuracy: 0.0558 - val_loss: 3.4904 - val_accuracy: 0.0550\n",
      "Epoch 6/50\n",
      "31367/31367 [==============================] - 10s 324us/step - loss: 3.4870 - accuracy: 0.0548 - val_loss: 3.4902 - val_accuracy: 0.0562\n",
      "Epoch 7/50\n",
      "31367/31367 [==============================] - 9s 294us/step - loss: 3.4869 - accuracy: 0.0577 - val_loss: 3.4894 - val_accuracy: 0.0524\n",
      "Epoch 8/50\n",
      "31367/31367 [==============================] - 9s 291us/step - loss: 3.4866 - accuracy: 0.0538 - val_loss: 3.4901 - val_accuracy: 0.0573\n",
      "Epoch 9/50\n",
      "31367/31367 [==============================] - 9s 289us/step - loss: 3.4865 - accuracy: 0.0575 - val_loss: 3.4896 - val_accuracy: 0.0573\n",
      "Epoch 10/50\n",
      "31367/31367 [==============================] - 10s 312us/step - loss: 3.4864 - accuracy: 0.0560 - val_loss: 3.4896 - val_accuracy: 0.0573\n",
      "Epoch 11/50\n",
      "31367/31367 [==============================] - 9s 287us/step - loss: 3.4865 - accuracy: 0.0560 - val_loss: 3.4900 - val_accuracy: 0.0573\n",
      "Epoch 12/50\n",
      "31367/31367 [==============================] - 9s 284us/step - loss: 3.4862 - accuracy: 0.0546 - val_loss: 3.4896 - val_accuracy: 0.0573\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31367/31367 [==============================] - 10s 306us/step - loss: 3.4865 - accuracy: 0.0554 - val_loss: 3.4897 - val_accuracy: 0.0562\n",
      "Epoch 14/50\n",
      "31367/31367 [==============================] - 11s 339us/step - loss: 3.4863 - accuracy: 0.0569 - val_loss: 3.4899 - val_accuracy: 0.0550\n",
      "Epoch 15/50\n",
      "31367/31367 [==============================] - 9s 286us/step - loss: 3.4861 - accuracy: 0.0570 - val_loss: 3.4895 - val_accuracy: 0.0550\n",
      "Epoch 16/50\n",
      "31367/31367 [==============================] - 9s 280us/step - loss: 3.4864 - accuracy: 0.0570 - val_loss: 3.4898 - val_accuracy: 0.0562\n",
      "Epoch 17/50\n",
      "31367/31367 [==============================] - 8s 270us/step - loss: 3.4860 - accuracy: 0.0557 - val_loss: 3.4889 - val_accuracy: 0.0562\n",
      "Epoch 18/50\n",
      "31367/31367 [==============================] - 10s 314us/step - loss: 3.4859 - accuracy: 0.0551 - val_loss: 3.4897 - val_accuracy: 0.0562\n",
      "Epoch 19/50\n",
      "31367/31367 [==============================] - 9s 282us/step - loss: 3.4862 - accuracy: 0.0542 - val_loss: 3.4901 - val_accuracy: 0.0562\n",
      "Epoch 20/50\n",
      "31367/31367 [==============================] - 9s 276us/step - loss: 3.4861 - accuracy: 0.0584 - val_loss: 3.4896 - val_accuracy: 0.0573\n",
      "Epoch 21/50\n",
      "31367/31367 [==============================] - 9s 284us/step - loss: 3.4862 - accuracy: 0.0567 - val_loss: 3.4899 - val_accuracy: 0.0573\n",
      "Epoch 22/50\n",
      "31367/31367 [==============================] - 8s 270us/step - loss: 3.4861 - accuracy: 0.0560 - val_loss: 3.4889 - val_accuracy: 0.0562\n",
      "Epoch 23/50\n",
      "31367/31367 [==============================] - 8s 267us/step - loss: 3.4862 - accuracy: 0.0544 - val_loss: 3.4898 - val_accuracy: 0.0550\n",
      "Epoch 24/50\n",
      "31367/31367 [==============================] - 8s 268us/step - loss: 3.4861 - accuracy: 0.0563 - val_loss: 3.4889 - val_accuracy: 0.0562\n",
      "Epoch 25/50\n",
      "31367/31367 [==============================] - 9s 272us/step - loss: 3.4861 - accuracy: 0.0579 - val_loss: 3.4894 - val_accuracy: 0.0550\n",
      "Epoch 26/50\n",
      "31367/31367 [==============================] - 8s 269us/step - loss: 3.4860 - accuracy: 0.0562 - val_loss: 3.4891 - val_accuracy: 0.0562\n",
      "Epoch 27/50\n",
      "31367/31367 [==============================] - 9s 275us/step - loss: 3.4862 - accuracy: 0.0559 - val_loss: 3.4891 - val_accuracy: 0.0573\n",
      "Epoch 28/50\n",
      "31367/31367 [==============================] - 8s 267us/step - loss: 3.4861 - accuracy: 0.0549 - val_loss: 3.4891 - val_accuracy: 0.0573\n",
      "Epoch 29/50\n",
      "31367/31367 [==============================] - 8s 266us/step - loss: 3.4864 - accuracy: 0.0569 - val_loss: 3.4897 - val_accuracy: 0.0562\n",
      "Epoch 30/50\n",
      "31367/31367 [==============================] - 9s 275us/step - loss: 3.4860 - accuracy: 0.0554 - val_loss: 3.4898 - val_accuracy: 0.0562\n",
      "Epoch 31/50\n",
      "31367/31367 [==============================] - 9s 274us/step - loss: 3.4860 - accuracy: 0.0562 - val_loss: 3.4890 - val_accuracy: 0.0573\n",
      "Epoch 32/50\n",
      "31367/31367 [==============================] - 8s 270us/step - loss: 3.1752 - accuracy: 0.1305 - val_loss: 1.8667 - val_accuracy: 0.4341\n",
      "Epoch 33/50\n",
      "31367/31367 [==============================] - 11s 356us/step - loss: 1.4169 - accuracy: 0.5628 - val_loss: 1.1003 - val_accuracy: 0.6784\n",
      "Epoch 34/50\n",
      "31367/31367 [==============================] - 10s 316us/step - loss: 0.9398 - accuracy: 0.7202 - val_loss: 0.7973 - val_accuracy: 0.7641\n",
      "Epoch 35/50\n",
      "31367/31367 [==============================] - 9s 285us/step - loss: 0.7109 - accuracy: 0.7878 - val_loss: 0.6776 - val_accuracy: 0.7995\n",
      "Epoch 36/50\n",
      "31367/31367 [==============================] - 9s 282us/step - loss: 0.5906 - accuracy: 0.8238 - val_loss: 0.5703 - val_accuracy: 0.8347\n",
      "Epoch 37/50\n",
      "31367/31367 [==============================] - 11s 347us/step - loss: 0.5033 - accuracy: 0.8501 - val_loss: 0.5091 - val_accuracy: 0.8508\n",
      "Epoch 38/50\n",
      "31367/31367 [==============================] - 10s 304us/step - loss: 0.4332 - accuracy: 0.8691 - val_loss: 0.4867 - val_accuracy: 0.8600\n",
      "Epoch 39/50\n",
      "31367/31367 [==============================] - 9s 275us/step - loss: 0.3883 - accuracy: 0.8836 - val_loss: 0.4278 - val_accuracy: 0.8735\n",
      "Epoch 40/50\n",
      "31367/31367 [==============================] - 9s 295us/step - loss: 0.3477 - accuracy: 0.8959 - val_loss: 0.3835 - val_accuracy: 0.8870\n",
      "Epoch 41/50\n",
      "31367/31367 [==============================] - 9s 295us/step - loss: 0.3203 - accuracy: 0.9034 - val_loss: 0.3718 - val_accuracy: 0.8915\n",
      "Epoch 42/50\n",
      "31367/31367 [==============================] - 9s 297us/step - loss: 0.2913 - accuracy: 0.9109 - val_loss: 0.3470 - val_accuracy: 0.8990\n",
      "Epoch 43/50\n",
      "31367/31367 [==============================] - 10s 326us/step - loss: 0.2714 - accuracy: 0.9161 - val_loss: 0.3218 - val_accuracy: 0.9086\n",
      "Epoch 44/50\n",
      "31367/31367 [==============================] - 10s 306us/step - loss: 0.2560 - accuracy: 0.9222 - val_loss: 0.3362 - val_accuracy: 0.9081\n",
      "Epoch 45/50\n",
      "31367/31367 [==============================] - 9s 284us/step - loss: 0.2422 - accuracy: 0.9257 - val_loss: 0.3370 - val_accuracy: 0.9026\n",
      "Epoch 46/50\n",
      "31367/31367 [==============================] - 9s 279us/step - loss: 0.2252 - accuracy: 0.9304 - val_loss: 0.3033 - val_accuracy: 0.9114\n",
      "Epoch 47/50\n",
      "31367/31367 [==============================] - 9s 273us/step - loss: 0.2071 - accuracy: 0.9348 - val_loss: 0.2976 - val_accuracy: 0.9160\n",
      "Epoch 48/50\n",
      "31367/31367 [==============================] - 9s 290us/step - loss: 0.2021 - accuracy: 0.9372 - val_loss: 0.2880 - val_accuracy: 0.9212\n",
      "Epoch 49/50\n",
      "31367/31367 [==============================] - 9s 272us/step - loss: 0.1863 - accuracy: 0.9419 - val_loss: 0.2829 - val_accuracy: 0.9221\n",
      "Epoch 50/50\n",
      "31367/31367 [==============================] - 9s 295us/step - loss: 0.1795 - accuracy: 0.9436 - val_loss: 0.2891 - val_accuracy: 0.9202\n",
      "Test Accuracy: 0.8459224069675376\n",
      "Train model part 5: \n",
      "Train on 31368 samples, validate on 7841 samples\n",
      "Epoch 1/50\n",
      "31368/31368 [==============================] - 10s 328us/step - loss: 3.5065 - accuracy: 0.0556 - val_loss: 3.4890 - val_accuracy: 0.0578\n",
      "Epoch 2/50\n",
      "31368/31368 [==============================] - 10s 326us/step - loss: 3.4891 - accuracy: 0.0562 - val_loss: 3.4887 - val_accuracy: 0.0551\n",
      "Epoch 3/50\n",
      "31368/31368 [==============================] - 10s 310us/step - loss: 3.4882 - accuracy: 0.0591 - val_loss: 3.4890 - val_accuracy: 0.0551\n",
      "Epoch 4/50\n",
      "31368/31368 [==============================] - 11s 338us/step - loss: 3.4879 - accuracy: 0.0563 - val_loss: 3.4870 - val_accuracy: 0.0551\n",
      "Epoch 5/50\n",
      "31368/31368 [==============================] - 10s 313us/step - loss: 3.4876 - accuracy: 0.0574 - val_loss: 3.4886 - val_accuracy: 0.0551\n",
      "Epoch 6/50\n",
      "31368/31368 [==============================] - 10s 318us/step - loss: 3.4875 - accuracy: 0.0567 - val_loss: 3.4868 - val_accuracy: 0.0551\n",
      "Epoch 7/50\n",
      "31368/31368 [==============================] - 10s 329us/step - loss: 3.4871 - accuracy: 0.0565 - val_loss: 3.4868 - val_accuracy: 0.0578\n",
      "Epoch 8/50\n",
      "31368/31368 [==============================] - 9s 283us/step - loss: 3.4874 - accuracy: 0.0569 - val_loss: 3.4873 - val_accuracy: 0.0551\n",
      "Epoch 9/50\n",
      "31368/31368 [==============================] - 8s 269us/step - loss: 3.4871 - accuracy: 0.0564 - val_loss: 3.4876 - val_accuracy: 0.0518\n",
      "Epoch 10/50\n",
      "31368/31368 [==============================] - 9s 275us/step - loss: 3.4865 - accuracy: 0.0561 - val_loss: 3.4785 - val_accuracy: 0.0515\n",
      "Epoch 11/50\n",
      "31368/31368 [==============================] - 9s 281us/step - loss: 1.9783 - accuracy: 0.4192 - val_loss: 0.8507 - val_accuracy: 0.7370\n",
      "Epoch 12/50\n",
      "31368/31368 [==============================] - 9s 273us/step - loss: 0.5953 - accuracy: 0.8137 - val_loss: 0.4406 - val_accuracy: 0.8584\n",
      "Epoch 13/50\n",
      "31368/31368 [==============================] - 9s 287us/step - loss: 0.3462 - accuracy: 0.8919 - val_loss: 0.3306 - val_accuracy: 0.8984\n",
      "Epoch 14/50\n",
      "31368/31368 [==============================] - 9s 298us/step - loss: 0.2633 - accuracy: 0.9153 - val_loss: 0.3165 - val_accuracy: 0.9037\n",
      "Epoch 15/50\n",
      "31368/31368 [==============================] - 10s 315us/step - loss: 0.1991 - accuracy: 0.9369 - val_loss: 0.2549 - val_accuracy: 0.9259\n",
      "Epoch 16/50\n",
      "31368/31368 [==============================] - 10s 317us/step - loss: 0.1639 - accuracy: 0.9474 - val_loss: 0.2412 - val_accuracy: 0.9301\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31368/31368 [==============================] - 10s 304us/step - loss: 0.1355 - accuracy: 0.9561 - val_loss: 0.2133 - val_accuracy: 0.9407\n",
      "Epoch 18/50\n",
      "31368/31368 [==============================] - 9s 297us/step - loss: 0.1053 - accuracy: 0.9670 - val_loss: 0.2016 - val_accuracy: 0.9454\n",
      "Epoch 19/50\n",
      "31368/31368 [==============================] - 9s 298us/step - loss: 0.0928 - accuracy: 0.9707 - val_loss: 0.2289 - val_accuracy: 0.9360\n",
      "Epoch 20/50\n",
      "31368/31368 [==============================] - 9s 300us/step - loss: 0.0801 - accuracy: 0.9740 - val_loss: 0.2027 - val_accuracy: 0.9441\n",
      "Epoch 21/50\n",
      "31368/31368 [==============================] - 9s 295us/step - loss: 0.0683 - accuracy: 0.9786 - val_loss: 0.2083 - val_accuracy: 0.9450\n",
      "Epoch 22/50\n",
      "31368/31368 [==============================] - 9s 298us/step - loss: 0.0631 - accuracy: 0.9792 - val_loss: 0.1902 - val_accuracy: 0.9533\n",
      "Epoch 23/50\n",
      "31368/31368 [==============================] - 9s 299us/step - loss: 0.0469 - accuracy: 0.9857 - val_loss: 0.1946 - val_accuracy: 0.9532\n",
      "Epoch 24/50\n",
      "31368/31368 [==============================] - 11s 337us/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.1882 - val_accuracy: 0.9557\n",
      "Epoch 25/50\n",
      "31368/31368 [==============================] - 9s 289us/step - loss: 0.0312 - accuracy: 0.9909 - val_loss: 0.2003 - val_accuracy: 0.9560\n",
      "Epoch 26/50\n",
      "31368/31368 [==============================] - 9s 301us/step - loss: 0.0376 - accuracy: 0.9888 - val_loss: 0.1970 - val_accuracy: 0.9559\n",
      "Epoch 27/50\n",
      "31368/31368 [==============================] - 9s 292us/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 0.2221 - val_accuracy: 0.9504\n",
      "Epoch 28/50\n",
      "31368/31368 [==============================] - 9s 281us/step - loss: 0.0411 - accuracy: 0.9867 - val_loss: 0.2023 - val_accuracy: 0.9541\n",
      "Epoch 29/50\n",
      "31368/31368 [==============================] - 9s 303us/step - loss: 0.0308 - accuracy: 0.9904 - val_loss: 0.2317 - val_accuracy: 0.9543\n",
      "Epoch 30/50\n",
      "31368/31368 [==============================] - 9s 297us/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.2217 - val_accuracy: 0.9560\n",
      "Epoch 31/50\n",
      "31368/31368 [==============================] - 9s 301us/step - loss: 0.0272 - accuracy: 0.9914 - val_loss: 0.2157 - val_accuracy: 0.9520\n",
      "Epoch 32/50\n",
      "31368/31368 [==============================] - 10s 307us/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.2153 - val_accuracy: 0.9584\n",
      "Epoch 33/50\n",
      "31368/31368 [==============================] - 10s 314us/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.2588 - val_accuracy: 0.9496\n",
      "Epoch 34/50\n",
      "31368/31368 [==============================] - 9s 289us/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 0.2048 - val_accuracy: 0.9584\n",
      "Epoch 35/50\n",
      "31368/31368 [==============================] - 9s 302us/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.2208 - val_accuracy: 0.9606\n",
      "Epoch 36/50\n",
      "31368/31368 [==============================] - 9s 287us/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.2238 - val_accuracy: 0.9552\n",
      "Epoch 37/50\n",
      "31368/31368 [==============================] - 9s 285us/step - loss: 0.0355 - accuracy: 0.9888 - val_loss: 0.2386 - val_accuracy: 0.9563\n",
      "Epoch 38/50\n",
      "31368/31368 [==============================] - 9s 285us/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.2260 - val_accuracy: 0.9578\n",
      "Epoch 39/50\n",
      "31368/31368 [==============================] - 9s 278us/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.2312 - val_accuracy: 0.9563\n",
      "Epoch 40/50\n",
      "31368/31368 [==============================] - 9s 279us/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.2189 - val_accuracy: 0.9621\n",
      "Epoch 41/50\n",
      "31368/31368 [==============================] - 9s 283us/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.2483 - val_accuracy: 0.9560\n",
      "Epoch 42/50\n",
      "31368/31368 [==============================] - 9s 298us/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.2731 - val_accuracy: 0.9510\n",
      "Epoch 43/50\n",
      "31368/31368 [==============================] - 10s 323us/step - loss: 0.0416 - accuracy: 0.9871 - val_loss: 0.2310 - val_accuracy: 0.9605\n",
      "Epoch 44/50\n",
      "31368/31368 [==============================] - 9s 293us/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.2098 - val_accuracy: 0.9640\n",
      "Epoch 45/50\n",
      "31368/31368 [==============================] - 9s 295us/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.2013 - val_accuracy: 0.9657\n",
      "Epoch 46/50\n",
      "31368/31368 [==============================] - 9s 297us/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.2110 - val_accuracy: 0.9659\n",
      "Epoch 47/50\n",
      "31368/31368 [==============================] - 9s 296us/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.2199 - val_accuracy: 0.9640\n",
      "Epoch 48/50\n",
      "31368/31368 [==============================] - 9s 295us/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.2182 - val_accuracy: 0.9658\n",
      "Epoch 49/50\n",
      "31368/31368 [==============================] - 9s 291us/step - loss: 8.6873e-04 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9670\n",
      "Epoch 50/50\n",
      "31368/31368 [==============================] - 9s 294us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.2262 - val_accuracy: 0.9672\n",
      "Test Accuracy: 0.876959619952494\n"
     ]
    }
   ],
   "source": [
    "s=np.arange(Cells.shape[0])\n",
    "np.random.seed(classes)\n",
    "np.random.shuffle(s)\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=np.random)\n",
    "# cv = KFold(n_splits=5, shuffle=False)\n",
    "count = 0\n",
    "for train_index, test_index in cv.split(Cells):\n",
    "#     print(\"Train Index: \", train_index, \"\\n\")\n",
    "#     print(\"Test Index: \", test_index)\n",
    "    count += 1\n",
    "    X_train, X_val, y_train, y_val = Cells[train_index], Cells[test_index], labels[train_index], labels[test_index]\n",
    "\n",
    "    print(\"Train model part {0}: \".format(count))\n",
    "    trainModel(X_train, X_val, y_train, y_val,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9315122723673792, 0.8646872525732383, 0.8561361836896278, 0.8459224069675376, 0.876959619952494]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Accuracy')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data_score)\n",
    "y_pos = np.arange(len(data_score))\n",
    "plt.bar(y_pos, data_score, color=(0.2, 0.4, 0.6, 0.6))\n",
    " \n",
    "# Custom Axis title\n",
    "plt.xlabel('Accuracy', fontweight='bold', color = 'orange', fontsize='17', horizontalalignment='center')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylib",
   "language": "python",
   "name": "pylib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
